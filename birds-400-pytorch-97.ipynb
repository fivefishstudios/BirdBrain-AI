{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-24T15:57:17.402117Z","iopub.status.busy":"2023-03-24T15:57:17.401562Z","iopub.status.idle":"2023-03-24T15:57:17.405610Z","shell.execute_reply":"2023-03-24T15:57:17.404917Z","shell.execute_reply.started":"2023-03-24T15:57:17.402074Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-03-24T15:57:25.934668Z","iopub.status.busy":"2023-03-24T15:57:25.934388Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.10.1+cpu)\n","\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7ff9e7a98210>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchvision/\u001b[0m\n","\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7ff9e7a98610>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchvision/\u001b[0m\n","\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7ff9e7a98950>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchvision/\u001b[0m\n"]}],"source":["#use torch=1.10.1 and torchvision=0.11.2\n","# !pip install -U torchvision\n","# !pip install timm"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision import datasets, transforms\n","from torch import nn, optim\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, sampler, random_split\n","from torchvision import models"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:01:12.027812Z","iopub.status.busy":"2022-01-16T21:01:12.027332Z","iopub.status.idle":"2022-01-16T21:01:12.03706Z","shell.execute_reply":"2022-01-16T21:01:12.035249Z","shell.execute_reply.started":"2022-01-16T21:01:12.027773Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('0.2.2', '2.0.0')"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["torchvision.__version__, torch.__version__ # ('0.11.2+cu102', '1.10.1+cu102')"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import os\n","import sys\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["import albumentations as A\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset_path = \"/kaggle/input/100-bird-species/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:01:16.439994Z","iopub.status.busy":"2022-01-16T21:01:16.439684Z","iopub.status.idle":"2022-01-16T21:01:16.449396Z","shell.execute_reply":"2022-01-16T21:01:16.44857Z","shell.execute_reply.started":"2022-01-16T21:01:16.439967Z"},"trusted":true},"outputs":[],"source":["class_dict = pd.read_csv(os.path.join(dataset_path, \"class_dict.csv\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:01:17.730558Z","iopub.status.busy":"2022-01-16T21:01:17.730288Z","iopub.status.idle":"2022-01-16T21:01:17.739301Z","shell.execute_reply":"2022-01-16T21:01:17.738497Z","shell.execute_reply.started":"2022-01-16T21:01:17.730528Z"},"trusted":true},"outputs":[],"source":["classes = list(class_dict['class'])\n","print(len(classes))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:11.203602Z","iopub.status.busy":"2022-01-16T21:05:11.203023Z","iopub.status.idle":"2022-01-16T21:05:11.21588Z","shell.execute_reply":"2022-01-16T21:05:11.214991Z","shell.execute_reply.started":"2022-01-16T21:05:11.203563Z"},"trusted":true},"outputs":[],"source":["def get_data_loaders(data_dir, batch_size=64, train = False):\n","    if train:\n","        transform = transforms.Compose([\n","            transforms.RandomHorizontalFlip(p=0.5),\n","            transforms.RandomVerticalFlip(p=0.5),\n","            transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter(), \n","                                                        transforms.GaussianBlur(3)]), p=0.1),\n","            transforms.Resize(256),\n","            transforms.CenterCrop(240),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","            transforms.RandomErasing(p=0.14, value='random')\n","        ])\n","        train_data = datasets.ImageFolder(os.path.join(data_dir, \"train/\"), transform=transform)\n","        print(f\"Found {len(train_data)} images for training with {len(train_data.classes)} classes\")\n","        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n","        return train_loader, len(train_data)\n","    \n","    else:\n","        transform = transforms.Compose([\n","            transforms.Resize(256),\n","            transforms.CenterCrop(240),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","        ])\n","        val_data = datasets.ImageFolder(os.path.join(data_dir, \"valid/\"), transform=transform)\n","        test_data = datasets.ImageFolder(os.path.join(data_dir, \"test/\"), transform=transform)\n","        print(f\"Found {len(val_data)} images for validation with {len(val_data.classes)} classes\")\n","        print(f\"Found {len(test_data)} images for testing with {len(test_data.classes)} classes\")\n","        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n","        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=2)\n","        return (val_loader, test_loader, len(val_data), len(test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:11.374588Z","iopub.status.busy":"2022-01-16T21:05:11.374369Z","iopub.status.idle":"2022-01-16T21:05:12.708153Z","shell.execute_reply":"2022-01-16T21:05:12.707378Z","shell.execute_reply.started":"2022-01-16T21:05:11.374563Z"},"trusted":true},"outputs":[],"source":["(train_loader, train_data_len) = get_data_loaders(dataset_path, 256, train=True)\n","(val_loader, test_loader, valid_data_len, test_data_len) = get_data_loaders(dataset_path, 64, train=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:12.709932Z","iopub.status.busy":"2022-01-16T21:05:12.709681Z","iopub.status.idle":"2022-01-16T21:05:12.71517Z","shell.execute_reply":"2022-01-16T21:05:12.714382Z","shell.execute_reply.started":"2022-01-16T21:05:12.709897Z"},"trusted":true},"outputs":[],"source":["dataloaders = {\n","    \"train\":train_loader,\n","    \"val\": val_loader\n","}\n","dataset_sizes = {\n","    \"train\":train_data_len,\n","    \"val\": valid_data_len\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:12.717225Z","iopub.status.busy":"2022-01-16T21:05:12.716705Z","iopub.status.idle":"2022-01-16T21:05:12.72461Z","shell.execute_reply":"2022-01-16T21:05:12.72373Z","shell.execute_reply.started":"2022-01-16T21:05:12.717188Z"},"trusted":true},"outputs":[],"source":["print(len(train_loader))\n","print(len(val_loader))\n","print(len(test_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:12.727078Z","iopub.status.busy":"2022-01-16T21:05:12.726772Z","iopub.status.idle":"2022-01-16T21:05:12.73404Z","shell.execute_reply":"2022-01-16T21:05:12.733128Z","shell.execute_reply.started":"2022-01-16T21:05:12.727042Z"},"trusted":true},"outputs":[],"source":["print(train_data_len, test_data_len, valid_data_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:13.779784Z","iopub.status.busy":"2022-01-16T21:05:13.778992Z","iopub.status.idle":"2022-01-16T21:05:18.968451Z","shell.execute_reply":"2022-01-16T21:05:18.966607Z","shell.execute_reply.started":"2022-01-16T21:05:13.779743Z"},"trusted":true},"outputs":[],"source":["dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","images = images.numpy() # convert images to numpy for display\n","\n","# plot the images in the batch, along with the corresponding labels\n","fig = plt.figure(figsize=(25, 4))\n","for idx in np.arange(20):\n","    ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n","    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n","    ax.set_title(classes[labels[idx]])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:18.971865Z","iopub.status.busy":"2022-01-16T21:05:18.971456Z","iopub.status.idle":"2022-01-16T21:05:19.009073Z","shell.execute_reply":"2022-01-16T21:05:19.005482Z","shell.execute_reply.started":"2022-01-16T21:05:18.971805Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:19.010749Z","iopub.status.busy":"2022-01-16T21:05:19.010498Z","iopub.status.idle":"2022-01-16T21:05:19.022215Z","shell.execute_reply":"2022-01-16T21:05:19.01875Z","shell.execute_reply.started":"2022-01-16T21:05:19.010717Z"},"trusted":true},"outputs":[],"source":["import timm\n","# from timm.loss import LabelSmoothingCrossEntropy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:19.369979Z","iopub.status.busy":"2022-01-16T21:05:19.368302Z","iopub.status.idle":"2022-01-16T21:05:19.420393Z","shell.execute_reply":"2022-01-16T21:05:19.419675Z","shell.execute_reply.started":"2022-01-16T21:05:19.369893Z"},"trusted":true},"outputs":[],"source":["## DEIT ##\n","# model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)\n","# for param in model.parameters():\n","#     param.requires_grad = False\n","# n_inputs = model.head.in_features\n","\n","# model.head = nn.Sequential(\n","#     nn.Linear(n_inputs,2048),\n","#     nn.SiLU(),\n","#     nn.Dropout(0.2),\n","#     nn.Linear(2048, len(classes))\n","# )\n","\n","# model = model.to(device)\n","# print(model.head)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## EFFICIENTNET B0\n","torch.backends.cudnn.benchmark = True\n","model = models.efficientnet_b1(pretrained=True)\n","for param in model.parameters():\n","    param.requires_grad = False\n","n_inputs = model.classifier[1].in_features\n","model.classifier = nn.Sequential(\n","    nn.Linear(n_inputs,2048),\n","    nn.SiLU(),\n","    nn.Dropout(0.2),\n","    nn.Linear(2048, len(classes))\n",")\n","\n","model = model.to(device)\n","print(model.classifier)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:19.429035Z","iopub.status.busy":"2022-01-16T21:05:19.424425Z","iopub.status.idle":"2022-01-16T21:05:19.439527Z","shell.execute_reply":"2022-01-16T21:05:19.438054Z","shell.execute_reply.started":"2022-01-16T21:05:19.428993Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss(label_smoothing=0.11)\n","criterion = criterion.to(device)\n","optimizer = optim.AdamW(model.classifier.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:19.443959Z","iopub.status.busy":"2022-01-16T21:05:19.443711Z","iopub.status.idle":"2022-01-16T21:05:19.452948Z","shell.execute_reply":"2022-01-16T21:05:19.45218Z","shell.execute_reply.started":"2022-01-16T21:05:19.443921Z"},"trusted":true},"outputs":[],"source":["training_history = {'accuracy':[],'loss':[]}\n","validation_history = {'accuracy':[],'loss':[]}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:19.458529Z","iopub.status.busy":"2022-01-16T21:05:19.458259Z","iopub.status.idle":"2022-01-16T21:05:19.469041Z","shell.execute_reply":"2022-01-16T21:05:19.46815Z","shell.execute_reply.started":"2022-01-16T21:05:19.458493Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","import time\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:19.475452Z","iopub.status.busy":"2022-01-16T21:05:19.475208Z","iopub.status.idle":"2022-01-16T21:05:19.490252Z","shell.execute_reply":"2022-01-16T21:05:19.48937Z","shell.execute_reply.started":"2022-01-16T21:05:19.475421Z"},"trusted":true},"outputs":[],"source":["exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:19.760252Z","iopub.status.busy":"2022-01-16T21:05:19.759846Z","iopub.status.idle":"2022-01-16T21:05:19.788232Z","shell.execute_reply":"2022-01-16T21:05:19.787326Z","shell.execute_reply.started":"2022-01-16T21:05:19.760204Z"},"trusted":true},"outputs":[],"source":["def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in tqdm(dataloaders[phase]):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","            \n","            if phase == 'train':\n","                training_history['accuracy'].append(epoch_acc)\n","                training_history['loss'].append(epoch_loss)\n","            elif phase == 'val':\n","                validation_history['accuracy'].append(epoch_acc)\n","                validation_history['loss'].append(epoch_loss)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T21:05:20.618232Z","iopub.status.busy":"2022-01-16T21:05:20.617755Z"},"trusted":true},"outputs":[],"source":["model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler,\n","                       num_epochs=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def test(model):\n","  test_loss = 0.0\n","  class_correct = list(0. for i in range(len(classes)))\n","  class_total = list(0. for i in range(len(classes)))\n","\n","  model.eval()\n","\n","  for data, target in tqdm(test_loader):\n","      if torch.cuda.is_available(): \n","          data, target = data.cuda(), target.cuda()\n","      with torch.no_grad():\n","        output = model(data)\n","        loss = criterion(output, target)\n","      test_loss += loss.item()*data.size(0)\n","      _, pred = torch.max(output, 1)    \n","      correct_tensor = pred.eq(target.data.view_as(pred))\n","      correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n","      if len(target) == 64:\n","        for i in range(64):\n","            label = target.data[i]\n","            class_correct[label] += correct[i].item()\n","            class_total[label] += 1\n","\n","  test_loss = test_loss/len(test_loader.dataset)\n","  print('Test Loss: {:.6f}\\n'.format(test_loss))\n","\n","  for i in range(len(classes)):\n","      if class_total[i] > 0:\n","          print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n","              classes[i], 100 * class_correct[i] / class_total[i],\n","              np.sum(class_correct[i]), np.sum(class_total[i])))\n","      else:\n","          print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n","\n","  print('\\nTest Accuracy (Overall): {:.4f} ({}/{})'.format(\n","      100. * np.sum(class_correct) / np.sum(class_total),\n","      np.sum(class_correct), np.sum(class_total)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test(model_ft)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["example = torch.rand(1, 3, 224, 224)\n","traced_script_module = torch.jit.trace(model_ft.cpu(), example)\n","traced_script_module.save(\"birds-325-efficientnetb1.zip\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
